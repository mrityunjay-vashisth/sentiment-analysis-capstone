{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Results & Performance Analysis\n",
    "## Sentiment Analysis Project\n",
    "\n",
    "**Objective:** Comprehensive analysis of VADER model performance on test sets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    roc_curve, auc\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test results\n",
    "social_results = pd.read_csv('../outputs/test_social_vader.csv')\n",
    "clothing_results = pd.read_csv('../outputs/test_clothing_vader.csv')\n",
    "\n",
    "print(f\"Social Media Results: {len(social_results):,} predictions\")\n",
    "print(f\"Clothing Results: {len(clothing_results):,} predictions\")\n",
    "\n",
    "print(\"\\nSample predictions (Social Media):\")\n",
    "social_results[['text', 'label', 'sentiment_label', 'sentiment_confidence']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Overall Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for both datasets\n",
    "def calculate_metrics(df, name):\n",
    "    y_true = df['label']\n",
    "    y_pred = df['sentiment_label']\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{name} - VADER Performance\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Target assessment\n",
    "    target = 0.80\n",
    "    if f1 >= target:\n",
    "        print(f\"âœ“ Target F1-score of {target:.0%} ACHIEVED!\")\n",
    "    else:\n",
    "        gap = target - f1\n",
    "        progress = (f1 / target) * 100\n",
    "        print(f\"âœ— Target F1-score of {target:.0%} not met\")\n",
    "        print(f\"  Current: {f1:.4f} ({f1*100:.2f}%)\")\n",
    "        print(f\"  Gap:     {gap:.4f} ({gap*100:.2f} percentage points)\")\n",
    "        print(f\"  Progress: {progress:.1f}% of target\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Calculate for both datasets\n",
    "social_metrics = calculate_metrics(social_results, \"Social Media\")\n",
    "clothing_metrics = calculate_metrics(clothing_results, \"Clothing Reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confusion Matrices (Enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "labels = ['negative', 'neutral', 'positive']\n",
    "\n",
    "# Social Media\n",
    "cm_social = confusion_matrix(social_results['label'], social_results['sentiment_label'], labels=labels)\n",
    "cm_social_norm = cm_social.astype('float') / cm_social.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm_social, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=labels, yticklabels=labels, ax=axes[0],\n",
    "           cbar_kws={'label': 'Count'}, linewidths=1, linecolor='gray')\n",
    "axes[0].set_title('Social Media - Confusion Matrix', fontsize=14, fontweight='bold', pad=15)\n",
    "axes[0].set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add percentage annotations\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        pct = cm_social_norm[i, j] * 100\n",
    "        axes[0].text(j + 0.5, i + 0.7, f'({pct:.1f}%)', \n",
    "                   ha='center', va='center', fontsize=9, color='gray')\n",
    "\n",
    "# Clothing Reviews\n",
    "cm_clothing = confusion_matrix(clothing_results['label'], clothing_results['sentiment_label'], labels=labels)\n",
    "cm_clothing_norm = cm_clothing.astype('float') / cm_clothing.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm_clothing, annot=True, fmt='d', cmap='Greens',\n",
    "           xticklabels=labels, yticklabels=labels, ax=axes[1],\n",
    "           cbar_kws={'label': 'Count'}, linewidths=1, linecolor='gray')\n",
    "axes[1].set_title('Clothing Reviews - Confusion Matrix', fontsize=14, fontweight='bold', pad=15)\n",
    "axes[1].set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add percentage annotations\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        pct = cm_clothing_norm[i, j] * 100\n",
    "        axes[1].text(j + 0.5, i + 0.7, f'({pct:.1f}%)', \n",
    "                   ha='center', va='center', fontsize=9, color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/final_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Per-Class Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get per-class metrics\n",
    "def get_per_class_metrics(df, name):\n",
    "    y_true = df['label']\n",
    "    y_pred = df['sentiment_label']\n",
    "    \n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Class': ['Negative', 'Neutral', 'Positive'],\n",
    "        'Precision': [report['negative']['precision'], \n",
    "                     report['neutral']['precision'], \n",
    "                     report['positive']['precision']],\n",
    "        'Recall': [report['negative']['recall'], \n",
    "                  report['neutral']['recall'], \n",
    "                  report['positive']['recall']],\n",
    "        'F1-Score': [report['negative']['f1-score'], \n",
    "                    report['neutral']['f1-score'], \n",
    "                    report['positive']['f1-score']],\n",
    "        'Support': [report['negative']['support'], \n",
    "                   report['neutral']['support'], \n",
    "                   report['positive']['support']]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name} - Per-Class Metrics:\")\n",
    "    print(metrics_df.to_string(index=False))\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "social_per_class = get_per_class_metrics(social_results, \"Social Media\")\n",
    "clothing_per_class = get_per_class_metrics(clothing_results, \"Clothing Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize per-class performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "x = np.arange(len(social_per_class))\n",
    "width = 0.25\n",
    "colors_metrics = ['#1976d2', '#388e3c', '#f57c00']\n",
    "\n",
    "# Social Media - Bar chart\n",
    "for i, metric in enumerate(metrics):\n",
    "    axes[0, 0].bar(x + i*width, social_per_class[metric], width, \n",
    "                  label=metric, color=colors_metrics[i], edgecolor='black')\n",
    "\n",
    "axes[0, 0].set_xlabel('Sentiment Class', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('Social Media - Per-Class Performance', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xticks(x + width)\n",
    "axes[0, 0].set_xticklabels(social_per_class['Class'])\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "axes[0, 0].set_ylim(0, 1.0)\n",
    "\n",
    "# Clothing - Bar chart\n",
    "for i, metric in enumerate(metrics):\n",
    "    axes[0, 1].bar(x + i*width, clothing_per_class[metric], width,\n",
    "                  label=metric, color=colors_metrics[i], edgecolor='black')\n",
    "\n",
    "axes[0, 1].set_xlabel('Sentiment Class', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('Clothing Reviews - Per-Class Performance', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xticks(x + width)\n",
    "axes[0, 1].set_xticklabels(clothing_per_class['Class'])\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "axes[0, 1].set_ylim(0, 1.0)\n",
    "\n",
    "# Support (sample size) comparison\n",
    "x_pos = np.arange(3)\n",
    "axes[1, 0].bar(x_pos - 0.2, social_per_class['Support'], 0.4, \n",
    "              label='Social Media', color='#2196f3', edgecolor='black')\n",
    "axes[1, 0].bar(x_pos + 0.2, clothing_per_class['Support'], 0.4,\n",
    "              label='Clothing', color='#4caf50', edgecolor='black')\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(['Negative', 'Neutral', 'Positive'])\n",
    "axes[1, 0].set_ylabel('Number of Samples', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('Test Set - Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# F1-Score comparison heatmap\n",
    "f1_comparison = pd.DataFrame({\n",
    "    'Social Media': social_per_class['F1-Score'].values,\n",
    "    'Clothing Reviews': clothing_per_class['F1-Score'].values\n",
    "}, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "sns.heatmap(f1_comparison.T, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "           vmin=0, vmax=1, ax=axes[1, 1], cbar_kws={'label': 'F1-Score'},\n",
    "           linewidths=1, linecolor='gray')\n",
    "axes[1, 1].set_title('F1-Score Comparison Heatmap', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Sentiment Class', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Dataset', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/final_per_class_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison Across Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Overall metrics comparison\n",
    "comparison_data = pd.DataFrame({\n",
    "    'Social Media': list(social_metrics),\n",
    "    'Clothing Reviews': list(clothing_metrics)\n",
    "}, index=['Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
    "\n",
    "comparison_data.T.plot(kind='bar', ax=axes[0], color=['#2196f3', '#4caf50', '#ff9800', '#f44336'],\n",
    "                      edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_title('VADER Model - Overall Performance Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Dataset', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xticklabels(['Social Media', 'Clothing Reviews'], rotation=0)\n",
    "axes[0].legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_ylim(0, 1.0)\n",
    "\n",
    "# Add target line\n",
    "axes[0].axhline(y=0.80, color='red', linestyle='--', linewidth=2, label='Target (80%)')\n",
    "axes[0].text(0.5, 0.82, 'Target: 80% F1', ha='center', fontweight='bold', \n",
    "            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "# Progress toward target\n",
    "datasets = ['Social Media', 'Clothing Reviews']\n",
    "f1_scores = [social_metrics[3], clothing_metrics[3]]\n",
    "progress = [(f1 / 0.80) * 100 for f1 in f1_scores]\n",
    "\n",
    "bars = axes[1].barh(datasets, progress, color=['#2196f3', '#4caf50'], edgecolor='black', linewidth=1.5)\n",
    "axes[1].axvline(x=100, color='red', linestyle='--', linewidth=2, label='Target (100%)')\n",
    "axes[1].set_xlabel('Progress Toward Target (%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Progress Toward 80% F1-Score Target', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "axes[1].set_xlim(0, 120)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, prog, f1) in enumerate(zip(bars, progress, f1_scores)):\n",
    "    axes[1].text(prog + 2, bar.get_y() + bar.get_height()/2, \n",
    "                f'{prog:.1f}% (F1: {f1:.3f})',\n",
    "                va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/final_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify misclassifications\n",
    "social_results['correct'] = social_results['label'] == social_results['sentiment_label']\n",
    "clothing_results['correct'] = clothing_results['label'] == clothing_results['sentiment_label']\n",
    "\n",
    "print(\"Social Media Misclassification Rate:\")\n",
    "print(f\"  Correct:   {social_results['correct'].sum():,} ({social_results['correct'].mean()*100:.2f}%)\")\n",
    "print(f\"  Incorrect: {(~social_results['correct']).sum():,} ({(~social_results['correct']).mean()*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nClothing Misclassification Rate:\")\n",
    "print(f\"  Correct:   {clothing_results['correct'].sum():,} ({clothing_results['correct'].mean()*100:.2f}%)\")\n",
    "print(f\"  Incorrect: {(~clothing_results['correct']).sum():,} ({(~clothing_results['correct']).mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples of misclassifications\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE MISCLASSIFICATIONS - Social Media\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "errors = social_results[~social_results['correct']].sample(n=5, random_state=42)\n",
    "for idx, row in errors.iterrows():\n",
    "    print(f\"\\nText: {row['text'][:100]}...\")\n",
    "    print(f\"  Actual: {row['label']:8s} | Predicted: {row['sentiment_label']:8s} | Confidence: {row['sentiment_confidence']:.3f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confidence Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze confidence scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Social Media\n",
    "for label in ['negative', 'neutral', 'positive']:\n",
    "    data = social_results[social_results['sentiment_label'] == label]['sentiment_confidence']\n",
    "    axes[0].hist(data, bins=30, alpha=0.6, label=label.capitalize(), edgecolor='black')\n",
    "\n",
    "axes[0].set_xlabel('Confidence Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Social Media - Prediction Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Clothing Reviews\n",
    "for label in ['negative', 'neutral', 'positive']:\n",
    "    data = clothing_results[clothing_results['sentiment_label'] == label]['sentiment_confidence']\n",
    "    axes[1].hist(data, bins=30, alpha=0.6, label=label.capitalize(), edgecolor='black')\n",
    "\n",
    "axes[1].set_xlabel('Confidence Score', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Clothing Reviews - Prediction Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/final_confidence_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(\"\\nConfidence Score Statistics:\")\n",
    "print(\"\\nSocial Media:\")\n",
    "print(social_results.groupby('sentiment_label')['sentiment_confidence'].describe())\n",
    "print(\"\\nClothing Reviews:\")\n",
    "print(clothing_results.groupby('sentiment_label')['sentiment_confidence'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final summary table\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': ['Test Samples', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Target Progress'],\n",
    "    'Social Media': [\n",
    "        f\"{len(social_results):,}\",\n",
    "        f\"{social_metrics[0]:.4f}\",\n",
    "        f\"{social_metrics[1]:.4f}\",\n",
    "        f\"{social_metrics[2]:.4f}\",\n",
    "        f\"{social_metrics[3]:.4f}\",\n",
    "        f\"{(social_metrics[3]/0.80)*100:.1f}%\"\n",
    "    ],\n",
    "    'Clothing Reviews': [\n",
    "        f\"{len(clothing_results):,}\",\n",
    "        f\"{clothing_metrics[0]:.4f}\",\n",
    "        f\"{clothing_metrics[1]:.4f}\",\n",
    "        f\"{clothing_metrics[2]:.4f}\",\n",
    "        f\"{clothing_metrics[3]:.4f}\",\n",
    "        f\"{(clothing_metrics[3]/0.80)*100:.1f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY - VADER MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(summary.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š Key Findings:\")\n",
    "print(\"  1. Social Media: 56.2% F1-score (70.3% of target)\")\n",
    "print(\"  2. Clothing Reviews: 38.8% F1-score (48.5% of target)\")\n",
    "print(\"  3. Balanced data (social media) performs better\")\n",
    "print(\"  4. Imbalanced data (clothing) shows bias toward majority class\")\n",
    "print(\"\\nâœ“ Analysis complete! All visualizations saved to reports/ folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
